{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705660ec-c781-483b-b563-6efd82a216de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src import FactorialWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c0b968f-ae93-4c1c-92d0-3edeb43710ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(seed = 123, num_samples = 1000, model_type = 0, rho_cov = 0.15, error_type = 0, censoring = 0.15):\n",
    "    df = pd.DataFrame()\n",
    "    np.random.seed(seed)\n",
    "    mu_cov = np.array([0.5, 0.5, 0.5, 0.5, 0.5])\n",
    "    sigma_cov = np.full((5, 5), rho_cov)\n",
    "    np.fill_diagonal(sigma_cov, 1)\n",
    "\n",
    "    data = np.random.multivariate_normal(mu_cov, sigma_cov, num_samples)\n",
    "    df[['X1', 'X2', 'X3', 'X4', 'X5']] = data\n",
    "\n",
    "    beta_1 = np.array([-1/4, 3/4, 0, 2/4, -1])\n",
    "    beta_2 = np.array([3/4, -1/4, -1, 0, 1/2])\n",
    "    beta_3 = np.array([-1, 0, 3/4, 1/2, -1/4])\n",
    "    betas = [beta_1, beta_2, beta_3]\n",
    "\n",
    "    for i in range(len(betas)):\n",
    "        beta = betas[i]\n",
    "        prob = 1/(1+np.exp(-df[['X1', 'X2', 'X3', 'X4', 'X5']] @ beta))\n",
    "        random_values = np.random.rand(len(df))\n",
    "        df[f'Z{i+1}'] = (random_values < prob).astype(int)\n",
    "        df[f'Z{i+1}'] = df[f'Z{i+1}'].replace(0, -1)                \n",
    "\n",
    "    errors = 0\n",
    "    if error_type == 0:\n",
    "        errors = np.random.gumbel(0, 1, len(df))\n",
    "    if error_type == 1:\n",
    "        errors = np.random.normal(0, 1, len(df))\n",
    "    if model_type == 0:\n",
    "        df['Y'] = df[['X1', 'X2', 'X3', 'X4', 'X5']].sum(axis = 1) * 2\n",
    "        df['Y'] += df[['Z1', 'Z2', 'Z3']].sum(axis = 1)\n",
    "        #Mean is [0.4, 0.4, 0.4]\n",
    "    if model_type == 1:\n",
    "        df['Y'] = df[['X1', 'X2', 'X3', 'X4', 'X5']].sum(axis = 1)\n",
    "        for i in ['X1', 'X2', 'X3', 'X4', 'X5']:\n",
    "            for j in ['Z1', 'Z2', 'Z3']:\n",
    "                df['Y'] += df[i] * df[j]\n",
    "        #Mean is [1, 1, 1]\n",
    "    if model_type == 2:\n",
    "        df['Y'] = np.sin(df['X1'])\n",
    "        df['Y'] += np.cos(df['X2'])\n",
    "        df['Y'] += (np.minimum(1, df['X1']) + df['X2']) * df['Z1']\n",
    "        for i in ['X1', 'X2', 'X3', 'X4', 'X5']:\n",
    "            for j in ['Z2', 'Z3']:\n",
    "                df['Y'] += df[i] * df[j] \n",
    "\n",
    "        #Mean is [0.3208, 1, 1]\n",
    "\n",
    "    df['Y'] += errors\n",
    "    df['T'] = np.exp(df['Y']/5)\n",
    "    df = df.drop(columns = ['Y'])\n",
    "    censored_max = np.random.uniform(low=0, high = 1/(2 * censoring), size=len(df))\n",
    "\n",
    "    ranks = np.argsort(np.argsort(df['T']))\n",
    "    quantiles = ranks / (len(df['T']) - 1)\n",
    "    df['C'] = np.quantile(df['T'], np.minimum(censored_max, 1))\n",
    "    df['delta'] = (quantiles <= censored_max).astype(int)\n",
    "    df['tilde_T'] = np.log(np.minimum(df['T'], df['C']))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "912c71d1-39af-4c90-82c2-fc211eea9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_Y(ans):\n",
    "    df = ans.copy()\n",
    "    theta = np.array([0]*8)\n",
    "\n",
    "    for i in range(100):\n",
    "        df['cond_Y'] = df[['X1', 'X2', 'X3', 'X4', 'X5', 'Z1', 'Z2', 'Z3']] @ theta\n",
    "        df['r_theta'] = df['tilde_T'] - df['cond_Y']\n",
    "        df = df.sort_values('r_theta').reset_index(drop = True)\n",
    "        \n",
    "        n = len(df)\n",
    "        frac = (n - df.index - 1)/(n - df.index)\n",
    "        df['F'] = 1 - (np.power(frac, df['delta'])).cumprod()\n",
    "        \n",
    "        df['cond_e'] = (df['r_theta'] * df['F'].diff())/(1 - df['F'])\n",
    "        df['cond_e'] = df['cond_e'].fillna(0)\n",
    "        df['cond_e'] = df['cond_e'].replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "        df = df.iloc[::-1].reset_index(drop=True)\n",
    "        length = (df['cond_e'].max() - df['cond_e'])\n",
    "        df['cond_e'] = df['cond_e'].cumsum().shift(1)/(length*3)\n",
    "        df['cond_e'] = df['cond_e'].fillna(df['cond_e'].mean())\n",
    "        D = df[['X1', 'X2', 'X3', 'X4', 'X5', 'Z1', 'Z2', 'Z3']]\n",
    "        D_mean = D.mean(axis = 0)\n",
    "        D_vec = D - D_mean\n",
    "        inverse = 1/(D_vec**2).sum(axis=1).sum()\n",
    "        \n",
    "        df['Y_impute'] = df['tilde_T']\n",
    "        \n",
    "        df.loc[df['delta'] == 0, 'Y_impute'] = df.loc[df['delta'] == 0, 'cond_Y'] + df.loc[df['delta'] == 0, 'cond_e']\n",
    "        df['Y_impute'] = np.maximum(df['Y_impute'], df['tilde_T'])\n",
    "        \n",
    "        Y_vec = df['Y_impute'] - df['Y_impute'].max()\n",
    "        theta = inverse * (D_vec.values * np.array(Y_vec)[:, np.newaxis]).sum(axis = 0)\n",
    "    \n",
    "    df = df.drop(columns = ['T', 'C', 'cond_Y', 'r_theta', 'F', 'cond_e'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6652f99e-7aff-42ab-aa4c-47e1f8ab0969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_test(random_seed, model_type, error_type, censoring):\n",
    "    df = gen_data(seed = random_seed, model_type = model_type, error_type = error_type, censoring = censoring)\n",
    "    df = impute_Y(df)\n",
    "    df['X0'] = 1\n",
    "\n",
    "    fw = FactorialWeights()\n",
    "    treat_cols = ['Z1', 'Z2', 'Z3']\n",
    "    cov_cols = ['X0', 'X1', 'X2', 'X3', 'X4', 'X5']\n",
    "\n",
    "    naive_estimators = []\n",
    "    for effect in ['Z1', 'Z2', 'Z3']:\n",
    "        ATE = df.loc[df[effect] == 1, 'tilde_T'].mean() - df.loc[df[effect] == -1, 'tilde_T'].mean()\n",
    "        ATE = float(ATE)\n",
    "        naive_estimators.append(ATE)\n",
    "\n",
    "    additive_estimators = [] \n",
    "    for effect in ['Z1', 'Z2', 'Z3']:\n",
    "        w = fw.additive_treat_model(df, treat_cols, cov_cols, [effect], weighting = 'variance')\n",
    "        ATE =  (df[effect] * w * df['Y_impute']).sum()/len(df)\n",
    "        ATE = float(ATE)\n",
    "        additive_estimators.append(ATE)\n",
    "\n",
    "    hetero_estimators = []\n",
    "    for effect in ['Z1', 'Z2', 'Z3']:\n",
    "        w = fw.heterogeneous_treat_model(df, treat_cols, cov_cols, [effect], weighting = 'variance')\n",
    "        ATE =  (df[effect] * w * df['Y_impute']).sum()/len(df)\n",
    "        ATE = float(ATE)\n",
    "        hetero_estimators.append(ATE)\n",
    "\n",
    "    return naive_estimators, additive_estimators, hetero_estimators\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f5a71bf-a1bc-4a9b-92c2-d44b0d757db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_suite(model_type, error_type, censoring, num_sim = 1000):\n",
    "    \n",
    "    fairs = {}\n",
    "    if model_type == 0:\n",
    "        fairs = {'Z1':0.4, 'Z2': 0.4, 'Z3': 0.4}\n",
    "    if model_type == 1:\n",
    "        fairs = {'Z1':1, 'Z2':1, 'Z3':1}\n",
    "    if model_type == 2:\n",
    "        fairs = {'Z1':0.3208, 'Z2':1, 'Z3':1}\n",
    "\n",
    "    results = {}\n",
    "    estimators = ['naive', 'additive', 'hetero']\n",
    "    estimands = ['Z1', 'Z2', 'Z3']\n",
    "\n",
    "    for estimator in estimators:\n",
    "        for estimand in estimands:\n",
    "            results[(estimator, estimand)] = []\n",
    "    \n",
    "    for sim in range(num_sim):\n",
    "        random_seed = np.random.randint(0, 10_000_000)\n",
    "        \n",
    "        e1, e2, e3 = generate_single_test(random_seed, model_type, error_type, censoring)\n",
    "\n",
    "        results[('naive', 'Z1')].append(e1[0])\n",
    "        results[('naive', 'Z2')].append(e1[1])\n",
    "        results[('naive', 'Z3')].append(e1[2])\n",
    "        results[('additive', 'Z1')].append(e2[0])\n",
    "        results[('additive', 'Z2')].append(e2[1])\n",
    "        results[('additive', 'Z3')].append(e2[2])\n",
    "        results[('hetero', 'Z1')].append(e3[0])\n",
    "        results[('hetero', 'Z2')].append(e3[1])\n",
    "        results[('hetero', 'Z3')].append(e3[2])\n",
    "\n",
    "        if sim % 100 == 0:\n",
    "            print(sim)\n",
    "\n",
    "    test_results = {}\n",
    "    for estimator in estimators:\n",
    "        for estimand in estimands:\n",
    "            arr = np.array(results[(estimator, estimand)])\n",
    "            bias = float(arr.mean() - fairs[estimand])\n",
    "            rmse = float(np.sqrt(((arr- fairs[estimand])**2).mean()))\n",
    "            test_results[(estimator, estimand)] = (bias, rmse)\n",
    "\n",
    "    test_results['setting'] = {'model_type':model_type, 'error_type':error_type, 'censoring':censoring}\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cd26ea-6370-492c-9303-9843be69f071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "test_res = generate_test_suite(0, 0, 0.15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3254def3-3ad9-4299-bfaa-4d2039149058",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [0, 1, 2]\n",
    "error_types = [0, 1] \n",
    "censoring = [0.15, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8bf5e8-f596-407c-bf07-8799c0c2d4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('naive', 'Z1'): (-0.09440690781186323, 0.10931146570208816),\n",
       " ('naive', 'Z2'): (-0.13945935011881033, 0.17293482600319132),\n",
       " ('naive', 'Z3'): (-0.12390828506809848, 0.14727345768480238),\n",
       " ('additive', 'Z1'): (-0.031809780846179025, 0.039574686688239595),\n",
       " ('additive', 'Z2'): (-0.044807314710182844, 0.051671454993808555),\n",
       " ('additive', 'Z3'): (-0.04179384798989283, 0.04420254384420213),\n",
       " ('hetero', 'Z1'): (-0.042257265350834905, 0.047963494945486095),\n",
       " ('hetero', 'Z2'): (-0.048617263842227476, 0.05486813960582897),\n",
       " ('hetero', 'Z3'): (-0.04777702947932777, 0.049382866054329656),\n",
       " 'setting': {'model_type': 0, 'error_type': 0, 'censoring': 0.15}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "409faee2-89e1-4cba-ae86-b2774be88ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.8866744219136813), np.float64(1.101382064357695))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = gen_data()\n",
    "df = impute_Y(df)\n",
    "\n",
    "df_small = df.loc[df['delta'] == 0].copy()\n",
    "\n",
    "df_small['Y_impute'].mean(), df['Y_impute'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fee295-19dd-44a6-9718-61dca7314e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
